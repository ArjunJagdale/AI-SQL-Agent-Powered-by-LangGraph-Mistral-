# ğŸ“Š AI CSV â†’ SQL Agent

An interactive agent that lets you upload a CSV file, ask questions in plain English, and get **natural language answers** (instead of raw tables).

Behind the scenes, the agent:

* âœ… Converts questions â†’ **SQL queries**
* âš¡ Executes SQL on your CSV (in-memory SQLite)
* ğŸ—£ï¸ Translates results into **concise answers**
* ğŸ”— Uses **LangGraph** to **structure multi-step reasoning** and make SQL generation + interpretation more reliable
* ğŸ—ï¸ Follows the **MCP (Modelâ€“Controllerâ€“Processor)** architectural pattern for clean modularity

---
## Demo - 

Try it live on Hugging Face Spaces:  
[AI CSV Agent on Hugging Face Spaces](https://huggingface.co/spaces/ajnx014/Natural-Language-to-SQL-Agent)

---
### Video

https://github.com/user-attachments/assets/e575c257-e161-4425-9999-4a4114b67df0


---

## ğŸ—ï¸ Architecture (MCP = Modelâ€“Controllerâ€“Processor)

âš ï¸ Note: here **MCP = Modelâ€“Controllerâ€“Processor**, not Anthropicâ€™s *Model Context Protocol*.

* **Processor (`processor.py`)**

  * Loads CSVs, validates structure, cleans column names.
  * Stores data in an **in-memory SQLite database**.
  * Provides dataset info and HTML helpers (for tables, errors, cards).

* **Model (`model.py`) + LangGraph**

  * The **LLM brain** of the system.
  * **LangGraph** provides a *graph-based workflow engine* for orchestrating steps like:

    1. **Interpretation** â€“ Parse the userâ€™s natural language question into structured intent.
    2. **SQL Generation** â€“ Ask the LLM to generate a valid SQLite query.
    3. **Validation** â€“ Sanitize SQL (allow only `SELECT`, check schema, reject unsafe ops).
    4. **Execution** â€“ Run the query against the SQLite database.
    5. **Summarization** â€“ Convert raw query results into a **clear natural-language answer**.
  * LangGraph makes this robust by treating each step as a **node in a graph** â†’ you can retry, branch, or recover gracefully when something fails.
  * Example: If SQL generation fails, LangGraph can automatically re-prompt the LLM with more schema details before moving forward.

* **Controller (`controller.py`)**

  * Orchestrates between Processor & Model.
  * Manages dataset stats, query history, and HTML formatting.
  * Adds guardrails for empty inputs or failed queries.

* **App (`app.py`)**

  * **Gradio UI** for uploads, queries, results, SQL preview, and history.
  * Includes helpful tips + example queries.

---

## ğŸš€ Why LangGraph?

LangGraph is key here because natural language â†’ SQL is **multi-step and error-prone**.
Without LangGraph, youâ€™d just â€œask the LLMâ€ and hope for the best. With LangGraph:

* You get a **structured pipeline** instead of a single fragile call.
* Failures can be retried or repaired (e.g., regenerate SQL if schema mismatch).
* You can **inject schema + sample data** at just the right stage.
* Results can be summarized differently depending on the query type (counts vs aggregations vs text searches).

This makes the whole system **far more reliable, interpretable, and extensible**.

